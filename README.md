# Justification-Based Belief Tracking System

Um sistema de manutenÃ§Ã£o de crenÃ§as neural-simbÃ³lico que combina rastreamento causal determinÃ­stico com propagaÃ§Ã£o semÃ¢ntica probabilÃ­stica, powered by LLMs.

## ğŸ¯ Conceito Central

Ao invÃ©s de apenas armazenar crenÃ§as isoladas, o sistema mantÃ©m um **grafo de justificaÃ§Ã£o** onde:
- **Nodes**: Beliefs (statements em linguagem natural) com confianÃ§a probabilÃ­stica
- **Edges**: RelaÃ§Ãµes de justificaÃ§Ã£o (A suporta B, A contradiz C)
- **PropagaÃ§Ã£o**: MudanÃ§as se propagam atravÃ©s do grafo via dois mecanismos:
  1. **Causal** (determinÃ­stico): atravÃ©s de links explÃ­citos de justificaÃ§Ã£o
  2. **SemÃ¢ntica** (probabilÃ­stico): atravÃ©s de similaridade de conteÃºdo
- **LLM Integration**: DetecÃ§Ã£o automÃ¡tica de relacionamentos e resoluÃ§Ã£o de conflitos via Gemini

## ğŸ—ï¸ Arquitetura

```
baye/
â”œâ”€â”€ src/baye/              # Package principal
â”‚   â”œâ”€â”€ __init__.py        # Exports pÃºblicos
â”‚   â”œâ”€â”€ belief_types.py    # Estruturas de dados core
â”‚   â”œâ”€â”€ justification_graph.py  # Motor principal
â”‚   â”œâ”€â”€ belief_estimation.py    # K-NN semÃ¢ntico
â”‚   â””â”€â”€ llm_agents.py      # Agentes PydanticAI + Gemini
â”œâ”€â”€ examples/              # Exemplos de uso
â”‚   â”œâ”€â”€ example_llm_integration.py
â”‚   â””â”€â”€ example_estimation_integrated.py
â”œâ”€â”€ tests/                 # Testes
â”‚   â””â”€â”€ test_estimation.py
â”œâ”€â”€ pyproject.toml         # Config uv
â””â”€â”€ README.md
```

## ğŸš€ InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/franklinbaldo/baye.git
cd baye

# Instale com uv
uv sync

# Configure API key do Gemini
export GOOGLE_API_KEY="your-gemini-api-key"
```

## ğŸ’¡ Uso RÃ¡pido

### Modo V1.5: Com LLM (Recomendado)

```python
from baye import Belief, detect_relationship, resolve_conflict
import asyncio

async def main():
    # Criar beliefs
    b1 = Belief(
        content="Third-party services are reliable",
        confidence=0.7,
        context="infrastructure"
    )

    lesson = Belief(
        content="Stripe API returned 500 errors",
        confidence=0.9,
        context="incident"
    )

    # Detectar relacionamento automaticamente via LLM
    analysis = await detect_relationship(b1, lesson)
    print(f"Relationship: {analysis.relationship}")  # "contradicts"
    print(f"Confidence: {analysis.confidence}")      # 0.70

    # Resolver conflito via LLM
    if analysis.relationship == "contradicts":
        resolution = await resolve_conflict(b1, lesson)
        print(f"Resolved: {resolution.resolved_belief}")
        # "While third-party services are generally reliable,
        #  critical paths like payments need defensive programming"

asyncio.run(main())
```

### Modo V1.0: Manual (sem LLM)

```python
from baye import JustificationGraph, Belief

# Criar grafo
graph = JustificationGraph(max_depth=4)

# Adicionar beliefs manualmente
b1 = graph.add_belief(
    content="APIs can fail unexpectedly",
    confidence=0.6,
    context="api_reliability"
)

b2 = graph.add_belief(
    content="Always validate API responses",
    confidence=0.7,
    context="best_practices",
    supported_by=[b1.id]
)

# Propagar mudanÃ§as
result = graph.propagate_from(origin_id=b1.id)
print(f"Updated {result.total_beliefs_updated} beliefs")
```

## ğŸ“Š Exemplo Completo

Execute o exemplo com LLM (requer API key):

```bash
export GOOGLE_API_KEY="your-key"
uv run python examples/example_llm_integration.py
```

**Output esperado:**
```
ğŸ§  Belief Tracking with PydanticAI + Gemini
======================================================================

ğŸ“– Scenario: Stripe API Failure

Initial beliefs:
  B1: Third-party payment services are generally reliable (conf: 0.7)
  B2: Always validate and handle API responses gracefully (conf: 0.6)
  B3: Established services like Stripe don't need defensive programming (conf: 0.4)

ğŸ’¥ Incident: Stripe API returned 500 errors during checkout flow

ğŸ” Step 1: Detecting relationships with existing beliefs...

  â€¢ CONTRADICTS B1
    Confidence: 0.70
    â†’ Third-party payment services are generally reliable...

  â€¢ SUPPORTS B2
    Confidence: 0.70
    â†’ Always validate and handle API responses gracefully...

ğŸ¤ Step 3: Resolving contradiction between lesson and B1...

  Resolved Belief:
    "While third-party payment services are generally reliable, specific
     incidents like Stripe API returning 500 errors can occur and severely
     impact revenue. Robust error handling and monitoring are essential."

  Confidence: 0.80
```

## ğŸ”‘ Conceitos-Chave

### 1. LLM-Powered Relationship Detection

Usa Gemini via PydanticAI para detectar automaticamente se beliefs:
- **SUPPORT**: Um fornece evidÃªncia para o outro
- **CONTRADICT**: NÃ£o podem ser verdadeiros simultaneamente
- **REFINE**: Um Ã© uma versÃ£o mais especÃ­fica do outro
- **UNRELATED**: Sem conexÃ£o lÃ³gica significativa

### 2. Conflict Resolution

Quando beliefs contradizem, o LLM gera uma belief nuanceada que:
- Reconhece aspectos vÃ¡lidos de ambos
- Identifica condiÃ§Ãµes onde cada um se aplica
- Fornece sÃ­ntese balanceada e acionÃ¡vel

### 3. Structured Outputs

Todos os agentes retornam Pydantic models validados:
```python
class RelationshipAnalysis(BaseModel):
    relationship: Literal["supports", "contradicts", "refines", "unrelated"]
    confidence: float
    explanation: str

class ConflictResolution(BaseModel):
    resolved_belief: str
    confidence: float
    reasoning: str
    supports_first: bool
    supports_second: bool
```

## ğŸ›£ï¸ Roadmap

### V1.0-minimal âœ…
- [x] Grafo causal bÃ¡sico
- [x] PropagaÃ§Ã£o determinÃ­stica
- [x] DetecÃ§Ã£o de ciclos
- [x] Teste Stripe funcionando

### V1.5 (LLM Integration) âœ… **CONCLUÃDO**
- [x] Relationship discovery via LLM (PydanticAI + Gemini)
- [x] Conflict resolution automÃ¡tico via LLM
- [x] Structured outputs com Pydantic models
- [x] Batch relationship detection
- [x] OrganizaÃ§Ã£o src/baye/
- [ ] PropagaÃ§Ã£o bidirecional (prÃ³ximo)
- [ ] Embeddings reais via Gemini (prÃ³ximo)

### V2.0 (Escalabilidade) ğŸ¯
- [ ] PersistÃªncia (Neo4j + vector DB)
- [ ] Batch propagation (mÃºltiplas lessons)
- [ ] Dashboard de visualizaÃ§Ã£o (NetworkX + Plotly)
- [ ] API REST para integraÃ§Ã£o

### V2.5 (InteligÃªncia) ğŸ§ 
- [ ] Aprendizado de pesos de edges
- [ ] Meta-beliefs ("confio mais em security beliefs")
- [ ] Temporal decay (beliefs antigas perdem relevÃ¢ncia)
- [ ] Active learning (sistema pede clarificaÃ§Ã£o quando incerto)

## ğŸ“š API Reference

### Core Types

```python
from baye import Belief, BeliefID, Confidence, RelationType

# Criar belief
belief = Belief(
    content="APIs can fail",
    confidence=0.8,
    context="reliability"
)

# Atualizar confianÃ§a
belief.update_confidence(delta=0.1)  # Aumenta para 0.9
```

### LLM Agents

```python
from baye import (
    detect_relationship,
    resolve_conflict,
    find_related_beliefs,
    check_gemini_api_key
)

# Verificar API key
check_gemini_api_key()  # Raises ValueError se nÃ£o configurada

# Detectar relacionamento
analysis = await detect_relationship(belief1, belief2)

# Resolver conflito
resolution = await resolve_conflict(belief1, belief2, context="optional")

# Encontrar beliefs relacionadas em batch
relationships = await find_related_beliefs(
    new_belief,
    existing_beliefs,
    min_confidence=0.7
)
```

### Graph Operations

```python
from baye import JustificationGraph

graph = JustificationGraph(max_depth=4)

# Adicionar belief
b = graph.add_belief(content="...", confidence=0.7)

# Linkar beliefs
graph.link_beliefs(parent_id, child_id, relation=RelationType.SUPPORTS)

# Propagar mudanÃ§as
result = graph.propagate_from(origin_id=b.id)
print(f"Updated: {result.total_beliefs_updated}")
print(f"Max depth: {result.max_depth_reached}")
```

## ğŸ§ª Testing

```bash
# Rodar todos os testes
uv run pytest tests/

# Teste especÃ­fico
uv run pytest tests/test_estimation.py -v

# Com coverage
uv run pytest --cov=src/baye tests/
```

## ğŸ¤ Contribuindo

Ãreas prioritÃ¡rias:
1. **Embeddings reais**: Integrar Gemini Embeddings API
2. **PropagaÃ§Ã£o bidirecional**: Supporters tambÃ©m devem ser atualizados
3. **VisualizaÃ§Ã£o**: Dashboard interativo
4. **Benchmarks**: Datasets de agent failures

## ğŸ“„ LicenÃ§a

MIT License - use livremente em projetos comerciais ou acadÃªmicos.

## ğŸ™ Agradecimentos

Inspirado por discussÃµes sobre Truth Maintenance Systems (TMS), Bayesian program learning, e arquiteturas de agentes autÃ´nomos.

---

**Status**: V1.5 (LLM Integration) âœ… CONCLUÃDO
**PrÃ³ximo**: V2.0 (embeddings reais + propagaÃ§Ã£o bidirecional)
**Autor**: Franklin Baldo ([@franklinbaldo](https://github.com/franklinbaldo))
