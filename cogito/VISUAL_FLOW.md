# Fluxo Visual do Sistema de Treino V2.0

## Ciclo Completo: Da ObservaÃ§Ã£o ao Gradiente

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PASSO 1: OBSERVAÃ‡ÃƒO EPISTÃŠMICA                â”‚
â”‚                                                                  â”‚
â”‚  Agent executa tarefa â†’ observa resultado â†’ reflete             â”‚
â”‚  Exemplo: API call falhou com timeout                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                PASSO 2: DECODIFICAÃ‡ÃƒO FORÃ‡ADA (Tool)             â”‚
â”‚                                                                  â”‚
â”‚  LLM DEVE gerar:                                                â”‚
â”‚  {                                                               â”‚
â”‚    "tool": "update_belief",                                      â”‚
â”‚    "parameters": {                                               â”‚
â”‚      "belief_id": "Ï†1",                                          â”‚
â”‚      "p_hat": 0.75,          â† Subjetividade do agent          â”‚
â”‚      "signal": 0.9,           â† ObservaÃ§Ã£o externa mapeada      â”‚
â”‚      "r": 0.8, "n": 1.0, "q": 0.9  â† Pesos UoU                 â”‚
â”‚      "provenance": {...}                                         â”‚
â”‚    }                                                             â”‚
â”‚  }                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PASSO 3: UPDATE-ON-USE (MemÃ³ria)                    â”‚
â”‚                                                                  â”‚
â”‚  CrenÃ§a Ï† antes: a=1.2, b=0.8  â†’ P(Ï†)=0.60                     â”‚
â”‚                                                                  â”‚
â”‚  EvidÃªncia nova:                                                 â”‚
â”‚    w = r Ã— n Ã— q = 0.8 Ã— 1.0 Ã— 0.9 = 0.72                      â”‚
â”‚    a' = a + wÂ·signal = 1.2 + 0.72Ã—0.9 = 1.848                  â”‚
â”‚    b' = b + wÂ·(1-signal) = 0.8 + 0.72Ã—0.1 = 0.872              â”‚
â”‚                                                                  â”‚
â”‚  CrenÃ§a Ï† depois: a=1.848, b=0.872  â†’ P(Ï†)=0.679               â”‚
â”‚                                                                  â”‚
â”‚  âœ… EvidÃªncia registrada com proveniÃªncia completa               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           PASSO 4: ESTIMAÃ‡ÃƒO K-NN (Alvo de Treino)               â”‚
â”‚                                                                  â”‚
â”‚  Buscar 5 vizinhos semÃ¢nticos de Ï†:                             â”‚
â”‚                                                                  â”‚
â”‚    Ï†â‚‚: "Validar inputs" (sim=0.85, P=0.80, u=0.2)              â”‚
â”‚    Ï†â‚ƒ: "Try-catch I/O" (sim=0.72, P=0.70, u=0.3)               â”‚
â”‚    Ï†â‚‡: "Timeouts comuns" (sim=0.68, P=0.65, u=0.4)             â”‚
â”‚    Ï†â‚‰: "Cache resultados" (sim=0.55, P=0.50, u=0.5)            â”‚
â”‚    Ï†â‚â‚‚: "Retry logic" (sim=0.48, P=0.75, u=0.3)                â”‚
â”‚                                                                  â”‚
â”‚  Pesos por incerteza:                                            â”‚
â”‚    wâ‚‚ = 1/(1+0.2) = 0.833  â†’ normalizado: 0.31                 â”‚
â”‚    wâ‚ƒ = 1/(1+0.3) = 0.769  â†’ normalizado: 0.28                 â”‚
â”‚    wâ‚‡ = 1/(1+0.4) = 0.714  â†’ normalizado: 0.26                 â”‚
â”‚    wâ‚‰ = 1/(1+0.5) = 0.667  â†’ normalizado: 0.24                 â”‚
â”‚    wâ‚â‚‚ = 1/(1+0.3) = 0.769 â†’ normalizado: 0.28                 â”‚
â”‚                                                                  â”‚
â”‚  p_knn = Î£(wáµ¢ Ã— Páµ¢)                                             â”‚
â”‚        = 0.31Ã—0.80 + 0.28Ã—0.70 + ... = 0.68                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            PASSO 5: MIXAGEM DE ALVOS (p_star)                    â”‚
â”‚                                                                  â”‚
â”‚  p* = Î»Â·signal + (1-Î»)Â·p_knn                                    â”‚
â”‚     = 0.7Ã—0.90 + 0.3Ã—0.68                                       â”‚
â”‚     = 0.63 + 0.204 = 0.834                                      â”‚
â”‚                                                                  â”‚
â”‚  Se consenso fraco (mean_u > 0.5):                              â”‚
â”‚    p* â† 0.3Ã—0.5 + 0.7Ã—0.834 = 0.734  (pull toward prior)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PASSO 6: CÃLCULO DA LOSS                            â”‚
â”‚                                                                  â”‚
â”‚  Brier Score:                                                    â”‚
â”‚    L_brier = (p_hat - p*)Â² = (0.75 - 0.834)Â² = 0.007           â”‚
â”‚                                                                  â”‚
â”‚  Peso por certeza da vizinhanÃ§a:                                 â”‚
â”‚    conf_weight = 1 - mean_uncertainty                           â”‚
â”‚               = 1 - 0.32 = 0.68                                 â”‚
â”‚                                                                  â”‚
â”‚  Loss ponderada:                                                 â”‚
â”‚    L_weighted = 0.007 Ã— 0.68 = 0.0048                           â”‚
â”‚                                                                  â”‚
â”‚  (Opcional) TensÃ£o dialÃ©tica:                                    â”‚
â”‚    Se Ï† CONTRADICTS Ïˆ:                                          â”‚
â”‚      L_tension = relu(0.1 - |p_Ï† + p_Ïˆ - 1|)                    â”‚
â”‚                                                                  â”‚
â”‚  (Opcional) ECE proxy (calibraÃ§Ã£o por bins)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PASSO 7: PROPAGAÃ‡ÃƒO LOCAL (Grafo)                        â”‚
â”‚                                                                  â”‚
â”‚  Î”conf = 0.679 - 0.60 = +0.079                                  â”‚
â”‚                                                                  â”‚
â”‚  Para cada vizinho via arestas:                                  â”‚
â”‚                                                                  â”‚
â”‚    Ï†â‚ƒ (SUPPORTS Ï†):                                             â”‚
â”‚      similarity = 0.72                                           â”‚
â”‚      dampening = 0.5 Ã— 0.72 = 0.36                              â”‚
â”‚      Î”Ï†â‚ƒ = +0.079 Ã— 0.36 = +0.028                               â”‚
â”‚      Ï†â‚ƒ: 0.700 â†’ 0.703 âœ“                                        â”‚
â”‚                                                                  â”‚
â”‚    Ï†â‚„ (CONTRADICTS Ï†):                                          â”‚
â”‚      similarity = 0.65                                           â”‚
â”‚      dampening = 0.3 Ã— 0.65 = 0.195                             â”‚
â”‚      Î”Ï†â‚„ = -0.079 Ã— 0.195 = -0.015                              â”‚
â”‚      Ï†â‚„: 0.500 â†’ 0.496 âœ“                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          PASSO 8: BUFFER DE TREINO                               â”‚
â”‚                                                                  â”‚
â”‚  Adicionar sample:                                               â”‚
â”‚  {                                                               â”‚
â”‚    "belief_id": "Ï†1",                                            â”‚
â”‚    "context": "Belief: APIs externas podem falhar...",          â”‚
â”‚    "p_hat": 0.75,          â† Input da LLM                       â”‚
â”‚    "p_star": 0.834,        â† Alvo calculado (K-NN + signal)     â”‚
â”‚    "uncertainties": 0.32,                                        â”‚
â”‚    "signal": 0.9,                                                â”‚
â”‚    "brier": 0.007,                                               â”‚
â”‚    "timestamp": "2025-11-08T10:30:00Z"                          â”‚
â”‚  }                                                               â”‚
â”‚                                                                  â”‚
â”‚  Quando buffer >= 100 samples â†’ Batch training                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PASSO 9: FINE-TUNING (Batch PeriÃ³dico)                   â”‚
â”‚                                                                  â”‚
â”‚  Cada N tarefas ou M samples:                                    â”‚
â”‚                                                                  â”‚
â”‚  1. Carregar batch do buffer                                     â”‚
â”‚  2. Forward pass da LLM â†’ hidden_states                         â”‚
â”‚  3. Calibration head â†’ p_hat_predicted                          â”‚
â”‚  4. Loss = MSE(p_hat_predicted, p_star_batch)                   â”‚
â”‚  5. Backward â†’ atualizar LoRA weights + calibration head        â”‚
â”‚  6. Limpar buffer                                                â”‚
â”‚                                                                  â”‚
â”‚  Resultado: LLM aprende a estimar p_hat calibrado               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PASSO 10: PRÃ“XIMA ITERAÃ‡ÃƒO                          â”‚
â”‚                                                                  â”‚
â”‚  Agent agora tem:                                                â”‚
â”‚   âœ… CrenÃ§a Ï† atualizada com proveniÃªncia                        â”‚
â”‚   âœ… MemÃ³ria justificatÃ³ria completa                             â”‚
â”‚   âœ… Modelo calibrado para futuras estimaÃ§Ãµes                    â”‚
â”‚   âœ… Grafo de justificaÃ§Ã£o consistente                           â”‚
â”‚                                                                  â”‚
â”‚  â†’ Loop continua para prÃ³xima tarefa                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Fluxo de Dados: Anatomia de um Update

```
Input (Agent/LLM)          Tool Processing           Output (Treino)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

belief_id: "Ï†"             1. Recuperar Ï†            p_star: 0.834
p_hat: 0.75            â”Œâ”€â†’ 2. UoU update        â”Œâ”€â†’ uncertainties: 0.32
signal: 0.9            â”‚   3. K-NN search       â”‚   brier: 0.007
r, n, q: 0.8,1.0,0.9   â”‚   4. Mixagem           â”‚   
provenance: {...}      â”‚   5. Loss calc         â”‚   [Training Buffer]
                       â”‚                        â”‚   â†’ Batch training
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â†’ Model update
```

---

## Grafo de JustificaÃ§Ã£o: Exemplo Visual

```
                    Ï†â‚: APIs podem falhar
                   (P=0.679, u=0.368)
                          â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚                 â”‚
            SUPPORTS          CONTRADICTS
                 â”‚                 â”‚
                 â†“                 â†“
        Ï†â‚ƒ: Try-catch I/O    Ï†â‚„: Confiar em
         (P=0.703, u=0.5)     serviÃ§os auth
                 â”‚             (P=0.496, u=0.5)
            SUPPORTS
                 â”‚
                 â†“
         Ï†â‚…: Logs ajudam
          (P=0.900, u=0.5)

Legenda:
  P = Confidence (probabilidade)
  u = Uncertainty (incerteza epistÃªmica)
  â†’ PropagaÃ§Ã£o flui pelas arestas com dampening
```

---

## K-NN SemÃ¢ntico: VisualizaÃ§Ã£o

```
              EspaÃ§o de Embeddings (2D projetado)

                     Ï†â‚‚ (P=0.80)
                        â—
                         â•²
                          â•² sim=0.85
                           â•²
                            â•²
                             â— Ï† (query)
                            â•±  P_knn=0.68
                  sim=0.72 â•±
                          â•±
                         â—
                     Ï†â‚ƒ (P=0.70)

  Quanto mais prÃ³ximo (maior similaridade),
  maior o peso no cÃ¡lculo de p_knn.
  
  CrenÃ§as com baixa incerteza contribuem mais.
```

---

## ComparaÃ§Ã£o: Antes vs Depois do Update

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ESTADO INICIAL (t=0)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CrenÃ§a Ï†â‚: "APIs externas podem falhar"        â”‚
â”‚   a=1.2, b=0.8                                  â”‚
â”‚   P(Ï†â‚) = 0.600                                 â”‚
â”‚   u(Ï†â‚) = 0.500                                 â”‚
â”‚   EvidÃªncias: 0                                 â”‚
â”‚   ProveniÃªncia: []                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
         [ObservaÃ§Ã£o: Timeout em API]
         [Agent estima p_hat=0.75]
         [Signal externo: 0.9]
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             ESTADO ATUALIZADO (t=1)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CrenÃ§a Ï†â‚: "APIs externas podem falhar"        â”‚
â”‚   a=1.848, b=0.872                              â”‚
â”‚   P(Ï†â‚) = 0.679 (+0.079) âœ“                     â”‚
â”‚   u(Ï†â‚) = 0.368 (â†“ mais certeza)               â”‚
â”‚   EvidÃªncias: 1                                 â”‚
â”‚   ProveniÃªncia:                                 â”‚
â”‚     - [2025-11-08] TimeoutError                â”‚
â”‚       source: task_execution                    â”‚
â”‚       weight: 0.72                              â”‚
â”‚       signal: 0.9                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## MÃ©tricas de CalibraÃ§Ã£o: InterpretaÃ§Ã£o

```
Brier Score = 0.007     â†’  Excelente (prÃ³ximo de 0)
ECE = 0.060             â†’  Calibrado (< 0.1 Ã© bom)

InterpretaÃ§Ã£o:
  - Agent estÃ¡ aprendendo a estimar probabilidades
    muito prÃ³ximas do consenso local (K-NN)
  - Ainda hÃ¡ espaÃ§o para melhoria (p_hat vs p_star)
  - Com mais treino, p_hat â†’ p_star

Objetivo: Minimizar Brier e ECE atravÃ©s do fine-tuning
```

---

## Auditabilidade: Rastreando uma DecisÃ£o

```
Query: "Por que o agent agora confia menos em serviÃ§os autenticados?"

Resposta auditÃ¡vel:
  
  1. CrenÃ§a Ï†â‚„: "Confiar em serviÃ§os autenticados"
     Estado atual: P=0.496 (queda de 0.004)
  
  2. Causa raiz (backtracking):
     â† PropagaÃ§Ã£o negativa de Ï†â‚ (CONTRADICTS)
     â† Ï†â‚ sofreu update positivo (+0.079)
     â† Ï†â‚ recebeu evidÃªncia forte:
        - Timestamp: 2025-11-08T10:30:00Z
        - Source: task_execution
        - Signal: 0.9 (timeout em API)
        - Weight: 0.72 (alta confiabilidade)
  
  3. Justificativa lÃ³gica:
     "Se APIs externas falham frequentemente,
      entÃ£o confiar cegamente em serviÃ§os autenticados
      Ã© menos seguro."
  
  4. EvidÃªncias adicionais que suportariam revisÃ£o:
     - Observar sucesso consistente de APIs auth
     - Distinguir entre falhas de rede vs auth
```

---

## PrÃ³ximos Passos de ImplementaÃ§Ã£o

```
Fase 1: Core [2 semanas]
  â”œâ”€ âœ… Esquema de dados (SQL + ChromaDB)
  â”œâ”€ âœ… Tool update_belief
  â”œâ”€ âœ… K-NN estimation
  â””â”€ âœ… UoU logic

Fase 2: Training [2 semanas]
  â”œâ”€ [ ] Calibration head (PyTorch)
  â”œâ”€ [ ] Loss functions implementadas
  â”œâ”€ [ ] Training loop com LoRA
  â””â”€ [ ] Inference pipeline

Fase 3: Robustez [1 semana]
  â”œâ”€ [ ] Diversified K-NN
  â”œâ”€ [ ] Uncertainty regularization
  â”œâ”€ [ ] PropagaÃ§Ã£o avanÃ§ada
  â””â”€ [ ] DetecÃ§Ã£o de equilÃ­brio

Fase 4: ProduÃ§Ã£o [1 semana]
  â”œâ”€ [ ] API REST
  â”œâ”€ [ ] Dashboard de auditoria
  â”œâ”€ [ ] Testes E2E
  â””â”€ [ ] DocumentaÃ§Ã£o final
```

---

**ConclusÃ£o**: Este sistema une o melhor de trÃªs mundos:

1. **SimbÃ³lico**: Grafo de justificaÃ§Ã£o explÃ­cito
2. **ProbabilÃ­stico**: Update-on-Use com pseudo-contagens
3. **Neural**: Fine-tuning da LLM via gradientes locais

Resultado: Um agente que **aprende com seus prÃ³prios atos** de forma auditÃ¡vel, calibrada e disciplinada. ğŸ¯
